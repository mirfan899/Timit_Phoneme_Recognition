exp_dir=exp/
corpus_reader=CorpusReader(num_train=224,
	batch_size=16,
	corpus=
<persephone.corpus.Corpus object at 0x7ff0365fb3c8>)
log_softmax=Tensor("LogSoftmax:0", shape=(?, ?, 41), dtype=float32)
batch_x=Tensor("batch_x:0", shape=(?, ?, 123), dtype=float32)
batch_x_lens=Tensor("batch_x_lens:0", shape=(?,), dtype=int32)
batch_y=SparseTensor(indices=Tensor("Placeholder_2:0", shape=(?, ?), dtype=int64), values=Tensor("Placeholder_1:0", shape=(?,), dtype=int32), dense_shape=Tensor("Placeholder:0", shape=(?,), dtype=int64))
optimizer=name: "Adam"
op: "NoOp"
input: "^Adam/update_layer_0/bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/fw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/fw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/fw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/bw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/bw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/bw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/bw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_0/bidirectional_rnn/bw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/fw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/fw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/fw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/bw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/bw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/bw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/bw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_1/bidirectional_rnn/bw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/fw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/fw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/fw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/fw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/fw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/bw/lstm_cell/kernel/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/bw/lstm_cell/bias/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/bw/lstm_cell/w_f_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/bw/lstm_cell/w_i_diag/ApplyAdam"
input: "^Adam/update_layer_2/bidirectional_rnn/bw/lstm_cell/w_o_diag/ApplyAdam"
input: "^Adam/update_Variable/ApplyAdam"
input: "^Adam/update_Variable_1/ApplyAdam"
input: "^Adam/Assign"
input: "^Adam/Assign_1"

ler=Tensor("Mean_1:0", shape=(), dtype=float32)
dense_decoded=Tensor("hyp_dense_decoded:0", shape=(?, ?), dtype=int64)
dense_ref=Tensor("SparseToDense:0", dtype=int32)
saved_model_path=
num_layers=3
hidden_size=250
beam_width=100
vocab_size=41
out_fw=Tensor("layer_2/bidirectional_rnn/fw/fw/transpose_1:0", shape=(?, ?, 250), dtype=float32)
out_bw=Tensor("layer_2/ReverseSequence:0", shape=(?, ?, 250), dtype=float32)
outputs_concat=Tensor("layer_2/concat:0", shape=(?, ?, 500), dtype=float32)
outputs=Tensor("Reshape:0", shape=(?, 500), dtype=float32)
logits=Tensor("logits:0", shape=(?, ?, 41), dtype=float32)
decoded=[<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fefb43f88d0>]
log_prob=Tensor("CTCBeamSearchDecoder:3", shape=(?, 1), dtype=float32)
loss=Tensor("CTCLoss:0", shape=(?,), dtype=float32)
cost=Tensor("Mean:0", shape=(), dtype=float32)
